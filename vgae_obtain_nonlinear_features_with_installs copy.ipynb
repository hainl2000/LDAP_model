{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.10/site-packages (3.10.5)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: torch in /opt/homebrew/lib/python3.10/site-packages (2.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/harrisnguyen/Library/Python/3.10/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.10/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/harrisnguyen/Library/Python/3.10/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/harrisnguyen/Library/Python/3.10/lib/python/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/lib/python3.10/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/harrisnguyen/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install matplotlib numpy pandas torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Convolutional Auto-Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplace normalization\n",
    "class LplsNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LplsNorm, self).__init__()\n",
    "\n",
    "    def forward(self, adjacency_matrix):\n",
    "        degree = torch.sum(adjacency_matrix, dim=-1)\n",
    "        diag = torch.diag(torch.pow(degree, -0.5))\n",
    "        out = diag.mm(adjacency_matrix).mm(diag)\n",
    "        return out\n",
    "\n",
    "# convolutional\n",
    "class Convolution(nn.Module):\n",
    "    def __init__(self, in_dimension, out_dimension):\n",
    "        super(Convolution, self).__init__()\n",
    "        self.LinearLayer = nn.Sequential(\n",
    "            nn.Linear(in_dimension, out_dimension),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, adjacency_matrix, feature):\n",
    "        mf = feature + torch.mm(adjacency_matrix, feature)\n",
    "        out = self.LinearLayer(mf)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE_Encoder(nn.Module):\n",
    "    def __init__(self, in_dimension, hidden_dimension, embedding_dimension):\n",
    "        super(VGAE_Encoder, self).__init__()\n",
    "        self.lpls_norm = LplsNorm()\n",
    "        \n",
    "        # Lớp GCN cơ sở\n",
    "        self.base_gcn = Convolution(in_dimension, hidden_dimension)\n",
    "        \n",
    "        # Hai lớp tuyến tính để tạo ra mean và log_var\n",
    "        self.gcn_mean = Convolution(hidden_dimension, embedding_dimension)\n",
    "        self.gcn_log_var = Convolution(hidden_dimension, embedding_dimension)\n",
    "\n",
    "    def forward(self, adj_matrix, features):\n",
    "        # 1. Chuẩn hóa ma trận kề\n",
    "        norm_adj = self.lpls_norm(adj_matrix)\n",
    "        \n",
    "        # 2. Đưa qua lớp GCN cơ sở\n",
    "        hidden = self.base_gcn(norm_adj, features)\n",
    "        \n",
    "        # 3. Tính mean và log_var\n",
    "        mean = self.gcn_mean(norm_adj, hidden)\n",
    "        log_var = self.gcn_log_var(norm_adj, hidden)\n",
    "        \n",
    "        return mean, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerProductDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InnerProductDecoder, self).__init__()\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Tái tạo ma trận kề bằng cách lấy z nhân với chuyển vị của nó\n",
    "        z_t = z.t()\n",
    "        adj_reconstructed = torch.mm(z, z_t)\n",
    "        return torch.sigmoid(adj_reconstructed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGAE_Model(nn.Module):\n",
    "    def __init__(self, in_dimension, hidden_dimension, embedding_dimension):\n",
    "        super(VGAE_Model, self).__init__()\n",
    "        self.encoder = VGAE_Encoder(in_dimension, hidden_dimension, embedding_dimension)\n",
    "        self.decoder = InnerProductDecoder()\n",
    "\n",
    "    def reparameterize(self, mean, log_var):\n",
    "        # Thủ thuật tái tham số hóa\n",
    "        if self.training:\n",
    "            std = torch.exp(0.5 * log_var)\n",
    "            # Lấy mẫu từ phân phối chuẩn N(0, 1)\n",
    "            eps = torch.randn_like(std) \n",
    "            return eps.mul(std).add_(mean)\n",
    "        else:\n",
    "            # Khi kiểm tra hoặc suy luận, chỉ cần dùng mean\n",
    "            return mean\n",
    "\n",
    "    def forward(self, adj_matrix, features):\n",
    "        # Mã hóa để lấy mean và log_var\n",
    "        mean, log_var = self.encoder(adj_matrix, features)\n",
    "        \n",
    "        # Lấy mẫu z từ không gian tiềm ẩn\n",
    "        z = self.reparameterize(mean, log_var)\n",
    "        \n",
    "        # Giải mã để tái tạo ma trận kề\n",
    "        adj_reconstructed = self.decoder(z)\n",
    "        \n",
    "        return adj_reconstructed, mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgae_loss_function(preds, labels, mean, log_var, num_nodes, pos_weight):\n",
    "    # 1. Reconstruction Loss\n",
    "    # Dùng Binary Cross Entropy với Logits để ổn định hơn\n",
    "    reconstruction_loss = F.binary_cross_entropy_with_logits(\n",
    "        preds.view(-1), labels.view(-1), pos_weight=pos_weight\n",
    "    )\n",
    "    \n",
    "    # 2. KL Divergence Loss\n",
    "    # Công thức tính KL divergence giữa N(mean, var) và N(0, 1)\n",
    "    kl_divergence = -0.5 / num_nodes * torch.mean(torch.sum(\n",
    "        1 + 2 * log_var - mean.pow(2) - (2 * log_var).exp(), dim=1\n",
    "    ))\n",
    "    \n",
    "    return reconstruction_loss + kl_divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preset parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665 --- 316 --- 295\n"
     ]
    }
   ],
   "source": [
    "dataset = \"dataset2\"\n",
    "lnc_mi = pd.read_csv('./our_dataset/' + dataset + '/interaction/lnc_mi.csv', index_col='0').values\n",
    "mi_di = pd.read_csv('./our_dataset/' + dataset + '/interaction/mi_di.csv', index_col='0').values\n",
    "lnc_di = pd.read_csv('./our_dataset/' + dataset + '/interaction/lnc_di.csv', index_col='0').values\n",
    "L_num = lnc_mi.shape[0]\n",
    "D_num = mi_di.shape[1]\n",
    "M_num = mi_di.shape[0]\n",
    "print(f\"{L_num} --- {D_num} --- {M_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.load('./our_dataset/' + dataset + '/A/A_1_1.npy')\n",
    "folds = 5\n",
    "in_dimension = A.shape[1]\n",
    "embedding_dimension = 128\n",
    "learn_rate = 1e-2\n",
    "weight_decay = 1e-4\n",
    "n_epochs = 200\n",
    "network_num = 4\n",
    "hidden_dimension=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VGAE\n",
      "Fold 1, Graph 1, Final Loss: 1.2912273406982422\n",
      "Fold 1, Graph 2, Final Loss: 1.2220141887664795\n",
      "Fold 1, Graph 3, Final Loss: 1.215523362159729\n",
      "Fold 1, Graph 4, Final Loss: 1.2143527269363403\n",
      "Fold 2, Graph 1, Final Loss: 1.2867391109466553\n",
      "Fold 2, Graph 2, Final Loss: 1.224853277206421\n",
      "Fold 2, Graph 3, Final Loss: 1.2187788486480713\n",
      "Fold 2, Graph 4, Final Loss: 1.21786367893219\n",
      "Fold 3, Graph 1, Final Loss: 1.2912451028823853\n",
      "Fold 3, Graph 2, Final Loss: 1.1752026081085205\n",
      "Fold 3, Graph 3, Final Loss: 1.1657506227493286\n",
      "Fold 3, Graph 4, Final Loss: 1.1656312942504883\n",
      "Fold 4, Graph 1, Final Loss: 1.2915308475494385\n",
      "Fold 4, Graph 2, Final Loss: 1.2181141376495361\n",
      "Fold 4, Graph 3, Final Loss: 1.2124003171920776\n",
      "Fold 4, Graph 4, Final Loss: 1.2117968797683716\n",
      "Fold 5, Graph 1, Final Loss: 1.2904375791549683\n",
      "Fold 5, Graph 2, Final Loss: 1.2178077697753906\n",
      "Fold 5, Graph 3, Final Loss: 1.211694598197937\n",
      "Fold 5, Graph 4, Final Loss: 1.2106609344482422\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Giả sử các hàm VGAE_Model và vgae_loss_function đã được định nghĩa ở trên\n",
    "\n",
    "print(\"Start training VGAE\")\n",
    "rds = []\n",
    "res = [] # List này sẽ lưu trữ 'mu'\n",
    "\n",
    "for fold in range(folds):\n",
    "    # CẢI TIẾN 1: Khởi tạo model và optimizer MỘT LẦN cho mỗi fold\n",
    "    # Điều này cho phép model học hỏi qua tất cả các đồ thị trong một fold.\n",
    "    model = VGAE_Model(in_dimension, hidden_dimension, embedding_dimension) # Giả sử dùng VGAE_Model đã định nghĩa\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    d = [] # Lưu kết quả tái tạo của fold hiện tại\n",
    "    e = [] # Lưu vector tiềm ẩn 'mu' của fold hiện tại\n",
    "\n",
    "    for i in range(network_num):\n",
    "        epoch = 0\n",
    "        A_numpy = np.load('./our_dataset/' + dataset + '/A/A_' + str(fold + 1) + '_' + str(i + 1) + '.npy')\n",
    "        A = torch.Tensor(A_numpy)\n",
    "        num_nodes = A.shape[0]\n",
    "\n",
    "        # CẢI TIẾN 2: Tạo ma trận kề với self-loops\n",
    "        adj_input = A + torch.eye(num_nodes)\n",
    "        \n",
    "        # CẢI TIẾN 3: Sử dụng ma trận đơn vị làm features ban đầu\n",
    "        features_input = torch.eye(num_nodes)\n",
    "\n",
    "        # (Tùy chọn nhưng khuyến khích) Tính pos_weight để xử lý đồ thị thưa\n",
    "        pos_weight = torch.tensor(float(num_nodes**2 - adj_input.sum()) / adj_input.sum())\n",
    "\n",
    "        while epoch < n_epochs:\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass với input đã được xử lý\n",
    "            reconstructed_A, mu, log_var = model(adj_input, features_input)\n",
    "            \n",
    "            # CẢI TIẾN 4: Gọi hàm loss với đầy đủ tham số\n",
    "            loss = vgae_loss_function(reconstructed_A, adj_input, mu, log_var, num_nodes, pos_weight)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch += 1\n",
    "            \n",
    "        # --- Phần đánh giá (Evaluation) ---\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Sử dụng cùng input đã xử lý để đánh giá\n",
    "            rd, mu, log_var = model(adj_input, features_input)\n",
    "            d.append(rd.cpu().numpy()) # Chuyển về numpy để lưu trữ nếu cần\n",
    "            \n",
    "            # Lưu 'mu' làm vector biểu diễn tiềm ẩn\n",
    "            e.append(mu.cpu().numpy())\n",
    "            \n",
    "        print(f\"Fold {fold + 1}, Graph {i + 1}, Final Loss: {loss.item()}\")\n",
    "    \n",
    "    res.append(e)\n",
    "    rds.append(d)\n",
    "\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Start training\")\n",
    "# rds = []\n",
    "# res = []\n",
    "# for fold in range(folds):\n",
    "#     d = []\n",
    "#     e = []\n",
    "#     for i in range(network_num):\n",
    "#         epoch = 0\n",
    "#         A = torch.Tensor(np.load('./our_dataset/' + dataset + '/A/A_' + str(fold + 1) + '_' + str(i + 1) + '.npy'))\n",
    "        # model = GraphConvolution(in_dimension, embedding_dimension)\n",
    "        # optimizer = torch.optim.Adam(model.parameters(), lr=learn_rate, weight_decay=weight_decay)\n",
    "        # loss_function = nn.MSELoss(reduction='mean')\n",
    "#         while epoch < n_epochs:\n",
    "#             model.train()\n",
    "#             optimizer.zero_grad()\n",
    "#             rd, re = model(A, A)\n",
    "#             loss = loss_function(rd, A)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             epoch += 1\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             rd, re = model(A, A)\n",
    "#             d.append(rd)\n",
    "#             e.append(re)\n",
    "#         print(f\"The layer {fold + 1} graph convolutional auto-encoder loss is {loss.detach().cpu().item()}\")\n",
    "#     res.append(e)\n",
    "#     rds.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x162fcfa60>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output_dir = './our_dataset/' + dataset + '/A_vgae_encoder'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for fold in range(folds):\n",
    "    for i in range(network_num):\n",
    "        file_path = os.path.join(output_dir, f'A_{fold + 1}_{i + 1}.npy')\n",
    "        np.save(file_path, res[fold][i])\n",
    "\n",
    "plt.matshow(rds[0][0], cmap=plt.cm.coolwarm, vmin=0, vmax=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
