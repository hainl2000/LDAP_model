{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AUC-ROC Curve Visualization for LDAP Model\n",
        "\n",
        "This notebook visualizes the ROC curves for the joint VGAE-LDAGM model across 5-fold cross-validation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "from scipy import interp\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import from main.py\n",
        "from main import JointVGAE_LDAGM, JointDataset, joint_train, joint_test\n",
        "import config\n",
        "\n",
        "# Set style for better-looking plots\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "dataset = config.DATASET\n",
        "\n",
        "# Device selection\n",
        "if config.DEVICE == \"cuda\" and torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif config.DEVICE == \"mps\" and torch.backends.mps.is_available():\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    if config.DEVICE in [\"cuda\", \"mps\"]:\n",
        "        print(f\"Warning: {config.DEVICE} not available, falling back to CPU\")\n",
        "\n",
        "print(f\"Using device: {device}\")\n",
        "print(f\"Dataset: {dataset}\")\n",
        "print(f\"Total folds: {config.TOTAL_FOLDS}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run 5-Fold Cross-Validation and Collect ROC Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Storage for ROC curves data\n",
        "tprs = []\n",
        "aucs = []\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "all_fold_results = []\n",
        "\n",
        "print(f\"Starting 5-fold cross-validation for {dataset}...\\n\")\n",
        "\n",
        "for fold in range(config.TOTAL_FOLDS):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"Processing Fold {fold + 1}/5\")\n",
        "    print(f\"{'='*50}\")\n",
        "    \n",
        "    # Load data indices\n",
        "    positive5foldsidx = np.load(\n",
        "        f\"./our_dataset/{dataset}/index/positive5foldsidx.npy\",\n",
        "        allow_pickle=True,\n",
        "    )\n",
        "    negative5foldsidx = np.load(\n",
        "        f\"./our_dataset/{dataset}/index/negative5foldsidx.npy\",\n",
        "        allow_pickle=True,\n",
        "    )\n",
        "    positive_ij = np.load(f\"./our_dataset/{dataset}/index/positive_ij.npy\")\n",
        "    negative_ij = np.load(f\"./our_dataset/{dataset}/index/negative_ij.npy\")\n",
        "    \n",
        "    train_positive_ij = positive_ij[positive5foldsidx[fold][\"train\"]]\n",
        "    train_negative_ij = negative_ij[negative5foldsidx[fold][\"train\"]]\n",
        "    test_positive_ij = positive_ij[positive5foldsidx[fold][\"test\"]]\n",
        "    test_negative_ij = negative_ij[negative5foldsidx[fold][\"test\"]]\n",
        "\n",
        "    # Load similarity matrices\n",
        "    di_semantic_similarity = np.load(f\"./our_dataset/{dataset}/multi_similarities/di_semantic_similarity.npy\")\n",
        "    di_gip_similarity = np.load(f\"./our_dataset/{dataset}/multi_similarities/di_gip_similarity_fold_{fold+1}.npy\")\n",
        "    lnc_gip_similarity = np.load(f\"./our_dataset/{dataset}/multi_similarities/lnc_gip_similarity_fold_{fold+1}.npy\")\n",
        "    lnc_func_similarity = np.load(f\"./our_dataset/{dataset}/multi_similarities/lnc_func_similarity_fold_{fold+1}.npy\")\n",
        "    mi_gip_similarity = np.load(f\"./our_dataset/{dataset}/multi_similarities/mi_gip_similarity.npy\")\n",
        "    mi_func_similarity = np.load(f\"./our_dataset/{dataset}/multi_similarities/mi_func_similarity.npy\")\n",
        "    \n",
        "    # Load interaction matrices\n",
        "    lnc_di = pd.read_csv(f'./our_dataset/{dataset}/interaction/lnc_di.csv')\n",
        "    lnc_di.set_index('0', inplace=True)\n",
        "    lnc_di = lnc_di.values\n",
        "    lnc_di_copy = copy.copy(lnc_di)\n",
        "    \n",
        "    lnc_mi = pd.read_csv(f'./our_dataset/{dataset}/interaction/lnc_mi.csv', index_col='0').values\n",
        "    mi_di = pd.read_csv(f'./our_dataset/{dataset}/interaction/mi_di.csv')\n",
        "    mi_di.set_index('0', inplace=True)\n",
        "    mi_di = mi_di.values\n",
        "    \n",
        "    # Get dimensions\n",
        "    num_diseases = di_semantic_similarity.shape[0]\n",
        "    num_lnc = lnc_gip_similarity.shape[0]\n",
        "    num_mi = mi_gip_similarity.shape[0]\n",
        "    lncRNALen = num_lnc\n",
        "    \n",
        "    # Remove test edges from training adjacency matrix\n",
        "    for ij in positive_ij[positive5foldsidx[fold]['test']]:\n",
        "        lnc_di_copy[ij[0], ij[1] - lncRNALen] = 0\n",
        "    \n",
        "    # Create adjacency matrices for each entity type\n",
        "    disease_adjacency_matrices = [\n",
        "        torch.tensor(di_semantic_similarity, dtype=torch.float32).to(device), \n",
        "        torch.tensor(di_gip_similarity, dtype=torch.float32).to(device)\n",
        "    ]\n",
        "    lnaRNA_adjacency_matrices = [\n",
        "        torch.tensor(lnc_gip_similarity, dtype=torch.float32).to(device), \n",
        "        torch.tensor(lnc_func_similarity, dtype=torch.float32).to(device)\n",
        "    ]\n",
        "    miRNA_adjacency_matrices = [\n",
        "        torch.tensor(mi_gip_similarity, dtype=torch.float32).to(device), \n",
        "        torch.tensor(mi_func_similarity, dtype=torch.float32).to(device)\n",
        "    ]\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = JointDataset(train_positive_ij, train_negative_ij, \"train\", dataset)\n",
        "    test_dataset = JointDataset(test_positive_ij, test_negative_ij, \"test\", dataset)\n",
        "    \n",
        "    # Prepare multi-view data structure\n",
        "    multi_view_data = {\n",
        "        'disease': disease_adjacency_matrices,\n",
        "        'lnc': lnaRNA_adjacency_matrices,\n",
        "        'mi': miRNA_adjacency_matrices\n",
        "    }\n",
        "    \n",
        "    # Prepare interaction matrices as tensors\n",
        "    lnc_di_tensor = torch.tensor(lnc_di_copy, dtype=torch.float32).to(device)\n",
        "    lnc_mi_tensor = torch.tensor(lnc_mi, dtype=torch.float32).to(device)\n",
        "    mi_di_tensor = torch.tensor(mi_di, dtype=torch.float32).to(device)\n",
        "    \n",
        "    print(f\"Training fold {fold + 1}...\")\n",
        "    \n",
        "    # Joint training\n",
        "    trained_model, loss_history = joint_train(\n",
        "        num_lnc=num_lnc,\n",
        "        num_diseases=num_diseases,\n",
        "        num_mi=num_mi,\n",
        "        train_dataset=train_dataset,\n",
        "        multi_view_data=multi_view_data,\n",
        "        lnc_di_interaction=lnc_di_tensor,\n",
        "        lnc_mi_interaction=lnc_mi_tensor,\n",
        "        mi_di_interaction=mi_di_tensor,\n",
        "        fold=fold,\n",
        "        device=device\n",
        "    )\n",
        "    \n",
        "    print(f\"Testing fold {fold + 1}...\")\n",
        "    \n",
        "    # Testing\n",
        "    test_labels, test_predictions = joint_test(\n",
        "        model=trained_model,\n",
        "        test_dataset=test_dataset,\n",
        "        multi_view_data=multi_view_data,\n",
        "        lnc_di_interaction=lnc_di_tensor,\n",
        "        lnc_mi_interaction=lnc_mi_tensor,\n",
        "        mi_di_interaction=mi_di_tensor,\n",
        "        fold=fold,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        device=device\n",
        "    )\n",
        "    \n",
        "    # Calculate ROC curve and AUC\n",
        "    fpr, tpr, thresholds = roc_curve(test_labels, test_predictions)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    \n",
        "    # Store results\n",
        "    aucs.append(roc_auc)\n",
        "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
        "    tprs[-1][0] = 0.0\n",
        "    \n",
        "    # Store fold info\n",
        "    all_fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'fpr': fpr,\n",
        "        'tpr': tpr,\n",
        "        'auc': roc_auc,\n",
        "        'thresholds': thresholds\n",
        "    })\n",
        "    \n",
        "    print(f\"Fold {fold + 1} AUC: {roc_auc:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"All folds completed!\")\n",
        "print(f\"Mean AUC: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
        "print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Individual ROC Curves for Each Fold\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create figure with individual fold ROC curves\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Plot ROC curve for each fold\n",
        "for i, result in enumerate(all_fold_results):\n",
        "    plt.plot(\n",
        "        result['fpr'], \n",
        "        result['tpr'], \n",
        "        alpha=0.6, \n",
        "        linewidth=2,\n",
        "        label=f\"Fold {result['fold']} (AUC = {result['auc']:.4f})\"\n",
        "    )\n",
        "\n",
        "# Plot diagonal line (random classifier)\n",
        "plt.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier (AUC = 0.5000)')\n",
        "\n",
        "# Formatting\n",
        "plt.xlabel('False Positive Rate', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Positive Rate', fontsize=14, fontweight='bold')\n",
        "plt.title(f'ROC Curves for All Folds\\nDataset: {dataset}', fontsize=16, fontweight='bold')\n",
        "plt.legend(loc='lower right', fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save figure\n",
        "plt.savefig(f'roc_curves_all_folds_{dataset}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Figure saved as: roc_curves_all_folds_{dataset}.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Mean ROC Curve with Confidence Interval\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate mean and std of TPR across folds\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_tpr[-1] = 1.0\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "std_auc = np.std(aucs)\n",
        "\n",
        "# Calculate standard deviation of TPR\n",
        "std_tpr = np.std(tprs, axis=0)\n",
        "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
        "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
        "\n",
        "# Create figure with mean ROC curve\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "# Plot individual fold ROC curves (lighter)\n",
        "for i, result in enumerate(all_fold_results):\n",
        "    ax.plot(\n",
        "        result['fpr'], \n",
        "        result['tpr'], \n",
        "        alpha=0.3, \n",
        "        linewidth=1.5,\n",
        "        color='gray'\n",
        "    )\n",
        "\n",
        "# Plot mean ROC curve\n",
        "ax.plot(\n",
        "    mean_fpr, \n",
        "    mean_tpr, \n",
        "    color='blue',\n",
        "    linewidth=3,\n",
        "    label=f'Mean ROC (AUC = {mean_auc:.4f} ± {std_auc:.4f})'\n",
        ")\n",
        "\n",
        "# Plot confidence interval\n",
        "ax.fill_between(\n",
        "    mean_fpr, \n",
        "    tprs_lower, \n",
        "    tprs_upper, \n",
        "    color='blue', \n",
        "    alpha=0.2,\n",
        "    label='± 1 std. dev.'\n",
        ")\n",
        "\n",
        "# Plot diagonal line (random classifier)\n",
        "ax.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random Classifier (AUC = 0.5000)')\n",
        "\n",
        "# Formatting\n",
        "ax.set_xlabel('False Positive Rate', fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel('True Positive Rate', fontsize=14, fontweight='bold')\n",
        "ax.set_title(f'Mean ROC Curve with Confidence Interval\\nDataset: {dataset}', \n",
        "             fontsize=16, fontweight='bold')\n",
        "ax.legend(loc='lower right', fontsize=12)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save figure\n",
        "plt.savefig(f'roc_curve_mean_{dataset}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Figure saved as: roc_curve_mean_{dataset}.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary Statistics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a summary table\n",
        "summary_data = {\n",
        "    'Fold': [f\"Fold {i+1}\" for i in range(config.TOTAL_FOLDS)] + ['Mean ± Std'],\n",
        "    'AUC': [f\"{auc_val:.4f}\" for auc_val in aucs] + [f\"{mean_auc:.4f} ± {std_auc:.4f}\"]\n",
        "}\n",
        "\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"AUC-ROC Summary Across All Folds\")\n",
        "print(\"=\"*50)\n",
        "print(summary_df.to_string(index=False))\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Save summary to CSV\n",
        "summary_df.to_csv(f'auc_roc_summary_{dataset}.csv', index=False)\n",
        "print(f\"\\nSummary saved as: auc_roc_summary_{dataset}.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Combined Visualization: All Folds + Mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a comprehensive figure with subplots\n",
        "fig = plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Subplot 1: All individual fold ROC curves\n",
        "ax1 = plt.subplot(1, 3, 1)\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, config.TOTAL_FOLDS))\n",
        "for i, result in enumerate(all_fold_results):\n",
        "    ax1.plot(\n",
        "        result['fpr'], \n",
        "        result['tpr'], \n",
        "        alpha=0.7, \n",
        "        linewidth=2,\n",
        "        color=colors[i],\n",
        "        label=f\"Fold {result['fold']} (AUC = {result['auc']:.4f})\"\n",
        "    )\n",
        "ax1.plot([0, 1], [0, 1], 'k--', linewidth=2)\n",
        "ax1.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Individual Fold ROC Curves', fontsize=14, fontweight='bold')\n",
        "ax1.legend(loc='lower right', fontsize=9)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_xlim([0.0, 1.0])\n",
        "ax1.set_ylim([0.0, 1.05])\n",
        "\n",
        "# Subplot 2: Mean ROC curve with confidence interval\n",
        "ax2 = plt.subplot(1, 3, 2)\n",
        "for i, result in enumerate(all_fold_results):\n",
        "    ax2.plot(result['fpr'], result['tpr'], alpha=0.2, linewidth=1.5, color='gray')\n",
        "ax2.plot(mean_fpr, mean_tpr, color='blue', linewidth=3,\n",
        "         label=f'Mean ROC (AUC = {mean_auc:.4f} ± {std_auc:.4f})')\n",
        "ax2.fill_between(mean_fpr, tprs_lower, tprs_upper, color='blue', alpha=0.2,\n",
        "                 label='± 1 std. dev.')\n",
        "ax2.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')\n",
        "ax2.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Mean ROC Curve', fontsize=14, fontweight='bold')\n",
        "ax2.legend(loc='lower right', fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_xlim([0.0, 1.0])\n",
        "ax2.set_ylim([0.0, 1.05])\n",
        "\n",
        "# Subplot 3: AUC distribution across folds\n",
        "ax3 = plt.subplot(1, 3, 3)\n",
        "fold_numbers = [i+1 for i in range(config.TOTAL_FOLDS)]\n",
        "bars = ax3.bar(fold_numbers, aucs, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
        "ax3.axhline(y=mean_auc, color='red', linestyle='--', linewidth=2, label=f'Mean AUC = {mean_auc:.4f}')\n",
        "ax3.axhline(y=mean_auc + std_auc, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)\n",
        "ax3.axhline(y=mean_auc - std_auc, color='orange', linestyle=':', linewidth=1.5, alpha=0.7)\n",
        "ax3.set_xlabel('Fold Number', fontsize=12, fontweight='bold')\n",
        "ax3.set_ylabel('AUC Score', fontsize=12, fontweight='bold')\n",
        "ax3.set_title('AUC Distribution Across Folds', fontsize=14, fontweight='bold')\n",
        "ax3.set_xticks(fold_numbers)\n",
        "ax3.set_ylim([min(aucs) - 0.05, max(aucs) + 0.05])\n",
        "ax3.legend(loc='lower right', fontsize=10)\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, (bar, auc_val) in enumerate(zip(bars, aucs)):\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{auc_val:.4f}',\n",
        "             ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
        "\n",
        "plt.suptitle(f'ROC Curve Analysis - Dataset: {dataset}', \n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save comprehensive figure\n",
        "plt.savefig(f'roc_comprehensive_analysis_{dataset}.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Comprehensive figure saved as: roc_comprehensive_analysis_{dataset}.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Analysis Complete\n",
        "\n",
        "This notebook has successfully:\n",
        "1. Trained and tested the joint VGAE-LDAGM model for 5-fold cross-validation\n",
        "2. Collected ROC curve data for each fold\n",
        "3. Generated individual fold ROC curves\n",
        "4. Computed and plotted the mean ROC curve with confidence intervals\n",
        "5. Created a comprehensive visualization showing all aspects of model performance\n",
        "6. Saved all figures and summary statistics\n",
        "\n",
        "Generated files:\n",
        "- `roc_curves_all_folds_{dataset}.png`: Individual fold ROC curves\n",
        "- `roc_curve_mean_{dataset}.png`: Mean ROC curve with confidence interval\n",
        "- `roc_comprehensive_analysis_{dataset}.png`: Complete analysis dashboard\n",
        "- `auc_roc_summary_{dataset}.csv`: Summary statistics table\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "comp5318-py311",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
